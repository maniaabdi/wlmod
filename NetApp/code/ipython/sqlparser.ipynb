{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: e\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Copyright (C) 2009-2018 the sqlparse authors and contributors\n",
    "# <see AUTHORS file>\n",
    "#\n",
    "# This example is part of python-sqlparse and is released under\n",
    "# the BSD License: https://opensource.org/licenses/BSD-3-Clause\n",
    "#\n",
    "# This example illustrates how to extract table names from nested\n",
    "# SELECT statements.\n",
    "#\n",
    "# See:\n",
    "# https://groups.google.com/forum/#!forum/sqlparse/browse_thread/thread/b0bd9a022e9d4895\n",
    "\n",
    "import sqlparse\n",
    "from sqlparse.sql import IdentifierList, Identifier\n",
    "from sqlparse.tokens import Keyword, DML\n",
    "\n",
    "\n",
    "def is_subselect(parsed):\n",
    "    if not parsed.is_group:\n",
    "        return False\n",
    "    for item in parsed.tokens:\n",
    "        if item.ttype is DML and item.value.upper() == 'SELECT':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_from_part(parsed):\n",
    "    from_seen = False\n",
    "    for item in parsed.tokens:\n",
    "        if from_seen:\n",
    "            if is_subselect(item):\n",
    "                for x in extract_from_part(item):\n",
    "                    yield x\n",
    "            elif item.ttype is Keyword:\n",
    "                return\n",
    "            else:\n",
    "                yield item\n",
    "        elif item.ttype is Keyword and item.value.upper() == 'FROM':\n",
    "            from_seen = True\n",
    "\n",
    "\n",
    "def extract_table_identifiers(token_stream):\n",
    "    for item in token_stream:\n",
    "        if isinstance(item, IdentifierList):\n",
    "            for identifier in item.get_identifiers():\n",
    "                yield identifier.get_name()\n",
    "        elif isinstance(item, Identifier):\n",
    "            yield item.get_name()\n",
    "        # It's a bug to check for Keyword here, but in the example\n",
    "        # above some tables names are identified as keywords...\n",
    "        elif item.ttype is Keyword:\n",
    "            yield item.value\n",
    "\n",
    "\n",
    "def extract_tables(sql):\n",
    "    stream = extract_from_part(sqlparse.parse(sql)[0])\n",
    "    return list(extract_table_identifiers(stream))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sql = \"\"\"\n",
    "    select    distinct e.tags[\"asup_id\"] as asup_id\n",
    "        , e.asup_key\n",
    "        , d.dvc_serial_no\n",
    "        , e.log_name\n",
    "        , e.event_date\n",
    "        , e.sequence_id\n",
    "        , e.severity\n",
    "        , e.event_type\n",
    "        , e.message\n",
    "        , e.reason\n",
    "        , e.diskName\n",
    "        , e.tags\n",
    "        , e.sys_hash\n",
    "        , d.dvc_model\n",
    "        , d.rg_id\n",
    "        , d.dvc_type\n",
    "        , d.dvc_label\n",
    "        , dvc_primary_path\n",
    "        , dvc_secondary_path\n",
    "        , d.dt\n",
    "from asuprep.ems_events_may2018 e\n",
    "join asuprep.dvc_device_may2018 d on d.asup_id = e.tags[\"asup_id\"]\n",
    "where d.dvc_serial_no = 'S20LNWAGB09910'\n",
    "    \"\"\"\n",
    "\n",
    "    tables = ', '.join(extract_tables(sql))\n",
    "    print('Tables: {0}'.format(tables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SELECT', 'DISTINCT', 'E.TAGS[\"ASUP_ID\"]', 'AS', 'ASUP_ID', ',', 'E.ASUP_KEY', ',', 'D.DVC_SERIAL_NO', ',', 'E.LOG_NAME', ',', 'E.EVENT_DATE', ',', 'E.SEQUENCE_ID', ',', 'E.SEVERITY', ',', 'E.EVENT_TYPE', ',', 'E.MESSAGE', ',', 'E.REASON', ',', 'E.DISKNAME', ',', 'E.TAGS', ',', 'E.SYS_HASH', ',', 'D.DVC_MODEL', ',', 'D.RG_ID', ',', 'D.DVC_TYPE', ',', 'D.DVC_LABEL', ',', 'DVC_PRIMARY_PATH', ',', 'DVC_SECONDARY_PATH', ',', 'D.DT', 'FROM', 'ASUPREP.EMS_EVENTS_MAY2018', 'E', 'JOIN', 'ASUPREP.DVC_DEVICE_MAY2018', 'D', 'ON', 'D.ASUP_ID', '=', 'E.TAGS[\"ASUP_ID\"]', 'WHERE', 'D.DVC_SERIAL_NO', '=', \"'S20LNWAGB09910'\"]\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    select    distinct e.tags[\"asup_id\"] as asup_id\n",
    "        , e.asup_key\n",
    "        , d.dvc_serial_no\n",
    "        , e.log_name\n",
    "        , e.event_date\n",
    "        , e.sequence_id\n",
    "        , e.severity\n",
    "        , e.event_type\n",
    "        , e.message\n",
    "        , e.reason\n",
    "        , e.diskName\n",
    "        , e.tags\n",
    "        , e.sys_hash\n",
    "        , d.dvc_model\n",
    "        , d.rg_id\n",
    "        , d.dvc_type\n",
    "        , d.dvc_label\n",
    "        , dvc_primary_path\n",
    "        , dvc_secondary_path\n",
    "        , d.dt\n",
    "from asuprep.ems_events_may2018 e\n",
    "join asuprep.dvc_device_may2018 d on d.asup_id = e.tags[\"asup_id\"]\n",
    "where d.dvc_serial_no = 'S20LNWAGB09910'\"\"\"\n",
    "\n",
    "sql_vector = list(filter(lambda a: a != '', sql.upper().replace('\\n', ' ').split(' ')))\n",
    "print(sql_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name    alias\n",
      "0           E.TAGS[\"ASUP_ID\"]  ASUP_ID\n",
      "1  ASUPREP.EMS_EVENTS_MAY2018        E\n",
      "2  ASUPREP.DVC_DEVICE_MAY2018        D\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import graph_tool.all as gt\n",
    "g = gt.Graph(directed= True)\n",
    "v_label = g.new_vertex_property(\"string\")\n",
    "\n",
    "alias_raw = []\n",
    "if 'AS' in sql_vector:\n",
    "    name = sql_vector[sql_vector.index('AS')-1]\n",
    "    alias = sql_vector[sql_vector.index('AS') + 1]\n",
    "    alias_raw.append({'name': name, 'alias': alias})\n",
    "\n",
    "if 'JOIN' in sql_vector:\n",
    "    reference_name = sql_vector[sql_vector.index('FROM')+1:sql_vector.index('JOIN')][0]\n",
    "    reference_alias = sql_vector[sql_vector.index('FROM')+1:sql_vector.index('JOIN')][1]\n",
    "    factor_name = sql_vector[sql_vector.index('JOIN')+1:sql_vector.index('ON')][0]\n",
    "    factor_alias = sql_vector[sql_vector.index('JOIN')+1:sql_vector.index('ON')][1]\n",
    "    alias_raw.append({'name': reference_name, 'alias': reference_alias})\n",
    "    alias_raw.append({'name': factor_name, 'alias': factor_alias})\n",
    "    \n",
    "    v0 = g.add_vertex() # join\n",
    "    v_label[v0] = 'from'\n",
    "    v1 = g.add_vertex() # join\n",
    "    g.add_edge(v0, v1)\n",
    "    v_label[v1] = 'join'\n",
    "    v2 = g.add_vertex() # ref table\n",
    "    v_label[v2] = reference_name\n",
    "    v3 = g.add_vertex() # fac table\n",
    "    v_label[v3] = factor_name\n",
    "    \n",
    "    g.add_edge(v1, v2)\n",
    "    g.add_edge(v1, v3)\n",
    "    \n",
    "    \n",
    "    v4 = g.add_vertex() # COND\n",
    "    v_label[v4] = 'COND'\n",
    "    g.add_edge(v1, v4)\n",
    "    \n",
    "    op1 = sql_vector[sql_vector.index('ON')+1:sql_vector.index('WHERE')][0]\n",
    "    cond = sql_vector[sql_vector.index('ON')+1:sql_vector.index('WHERE')][1]\n",
    "    op2 = sql_vector[sql_vector.index('ON')+1:sql_vector.index('WHERE')][2]\n",
    "    \n",
    "    v5 = g.add_vertex() # op1\n",
    "    v_label[v5] = op1\n",
    "    g.add_edge(v4, v5)\n",
    "    \n",
    "    v6 = g.add_vertex() # operation\n",
    "    v_label[v6] = cond\n",
    "    g.add_edge(v4, v6)\n",
    "    \n",
    "    v7 = g.add_vertex() # op2\n",
    "    v_label[v7] = op2\n",
    "    g.add_edge(v4, v7)\n",
    "    g.vertex_properties[\"label\"] = v_label\n",
    "    \n",
    "gt.graph_draw(g, vertex_text=g.vp.label, vertex_font_size=8, \n",
    "              vertex_text_color = 'black', vertex_fill_color = 'white', vertex_color='black',\n",
    "              output_size=(800, 800), output=\"query1.png\")\n",
    "    \n",
    "alias_df = pd.DataFrame(data=alias_raw)\n",
    "print(alias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
